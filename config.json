{"training_args": {"warmup_ratio": 0.1,
                   "lr_scheduler_type": "cosine",
                   "optim": "adafactor",
                   "gradient_accumulation_steps": 1,
                   "learning_rate": 5e-4,
                   "per_device_train_batch_size": 4,
                   "per_device_eval_batch_size": 1,
                   "num_train_epochs": 3,
                   "output_dir": ".",
                   "overwrite_output_dir": true,
                   "load_best_model_at_end": true,
                   "fp16": true,
                   "seed": 42,
                   "save_total_limit": 1,
                   "logging_steps": 250,      
                   "eval_steps": 250,
                   "evaluation_strategy": "steps",
                   "save_strategy": "steps",
                   "metric_for_best_model": "MAP@3",
                   "report_to": "wandb"},
 "wandb": {"notes": "Usual mix r=16 mlm",
           "tags": ["deberta", "mcq"],
           "name": "data8k_250_mlm"},
 "output_dir": "models/deberta/deberta_250_mlm"
}